# ğŸ¤– Detector de SegmentaciÃ³n 3D para Steering Rack

Sistema de detecciÃ³n y segmentaciÃ³n en tiempo real usando YOLOv8 con cÃ¡mara RGB-D en ROS2.

## ğŸ“‹ Requisitos Previos

- Ubuntu 22.04
- ROS2 Humble
- Python 3.10
- CUDA 12.x (opcional, para GPU)

## ğŸ”§ InstalaciÃ³n del Entorno Virtual

### 1. Crear el entorno virtual

```bash
cd ~/misCosas/steering
python3 -m venv yolo_train_env
```

### 2. Activar el entorno

```bash
source ~/misCosas/steering/yolo_train_env/bin/activate
```

### 3. Actualizar pip

```bash
pip install --upgrade pip
```

### 4. Instalar dependencias principales

```bash
# PyTorch con soporte CUDA 12.8
pip install torch==2.9.1 torchvision==0.24.1 --index-url https://download.pytorch.org/whl/cu128

# YOLO y Ultralytics
pip install ultralytics==8.4.7

# OpenCV con mÃ³dulos contrib
pip install opencv-contrib-python==4.10.0.84

# Dependencias cientÃ­ficas
pip install numpy==1.26.4
pip install scipy==1.15.3
pip install matplotlib==3.10.8

# AnÃ¡lisis de datos
pip install polars==1.37.1
pip install psutil==7.2.1

# Utilidades
pip install pyyaml==6.0.3
pip install requests==2.32.5
pip install certifi==2026.1.4
```

### 5. Instalar bridge de ROS2 (fuera del venv)

**IMPORTANTE:** Desactiva el entorno virtual primero:

```bash
deactivate
```

Luego instala el bridge de CV (esto debe hacerse con el Python del sistema):

```bash
sudo apt update
sudo apt install ros-humble-cv-bridge ros-humble-vision-opencv python3-opencv
```

## ğŸ“ Estructura del Proyecto

```
ros2_robotiq_gripper-humble/
â”œâ”€â”€ launch/
â”œâ”€â”€ scripts_vision/
â”‚   â””â”€â”€ segment/
â”‚       â””â”€â”€ realtime_seg_detector.py
â”œâ”€â”€ weights/                    # â† Crear esta carpeta
â”‚   â””â”€â”€ best.pt                # â† Copiar tu modelo aquÃ­
â”œâ”€â”€ urdf/
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ package.xml
â””â”€â”€ README_ENV.md              # â† Este archivo
```

## ğŸš€ ConfiguraciÃ³n del Script

### 1. Copiar el modelo entrenado

```bash
# Crear carpeta de pesos
mkdir -p ~/ros2_ws/src/ros2_robotiq_gripper-humble/weights

# Copiar el modelo (ajusta la ruta origen segÃºn donde estÃ© tu best.pt)
cp ~/misCosas/steering/runs/segment/runs/segment/steering_segmentation/weights/best.pt \
   ~/ros2_ws/src/ros2_robotiq_gripper-humble/weights/
```

### 2. Modificar la ruta en el script

Edita `realtime_seg_detector.py` y cambia la lÃ­nea del model_path:

```python
# MODELO DE SEGMENTACION (V4)
model_path = os.path.join(
    os.path.dirname(__file__),
    '..',
    '..',
    'weights',
    'best.pt'
)
```

### 3. Hacer el script ejecutable

```bash
chmod +x ~/ros2_ws/src/ros2_robotiq_gripper-humble/scripts_vision/segment/realtime_seg_detector.py
```

## â–¶ï¸ EjecuciÃ³n

### OpciÃ³n 1: Con el entorno virtual activado

```bash
# Terminal 1: Activar entorno
source ~/misCosas/steering/yolo_train_env/bin/activate
source ~/ros2_ws/install/setup.bash

# Ejecutar el nodo
ros2 run ros2_robotiq_gripper-humble realtime_seg_detector.py
```

### OpciÃ³n 2: Script de launcher automatizado

Crea un script `run_detector.sh`:

```bash
#!/bin/bash
source ~/misCosas/steering/yolo_train_env/bin/activate
source ~/ros2_ws/install/setup.bash
ros2 run ros2_robotiq_gripper-humble realtime_seg_detector.py
```

Hazlo ejecutable y Ãºsalo:

```bash
chmod +x run_detector.sh
./run_detector.sh
```

## ğŸ“Š Topics Publicados

- `/steering_rack_centroid` (geometry_msgs/Point): Centroide 2D
- `/steering_rack_pose` (geometry_msgs/PoseStamped): Pose 3D con orientaciÃ³n

## ğŸ“¸ Topics Suscritos

- `/rgb` (sensor_msgs/Image): Imagen RGB
- `/depth` (sensor_msgs/Image): Mapa de profundidad

## ğŸ® Controles

- **Q**: Salir del programa
- **Sliders en ventana "Masked Depth Map"**:
  - `Min Z (cm)`: Profundidad mÃ­nima visible
  - `Max Z (cm)`: Profundidad mÃ¡xima visible

## ğŸ› SoluciÃ³n de Problemas

### Error: "No module named 'ultralytics'"

```bash
source ~/misCosas/steering/yolo_train_env/bin/activate
pip install ultralytics
```

### Error: "No module named 'cv_bridge'"

```bash
sudo apt install ros-humble-cv-bridge python3-opencv
```

### Error: CUDA out of memory

Reduce el tamaÃ±o de las imÃ¡genes o usa CPU:

```python
# En el script, modifica la predicciÃ³n:
results = self.model.predict(img, conf=0.5, verbose=False, device='cpu')
```

### Las ventanas OpenCV no aparecen

Verifica que tengas display configurado:

```bash
echo $DISPLAY
# DeberÃ­a mostrar algo como :0 o :1
```

## ğŸ“¦ Dependencias Completas (requirements.txt)

Para facilitar la instalaciÃ³n, puedes crear un `requirements.txt`:

```txt
torch==2.9.1
torchvision==0.24.1
ultralytics==8.4.7
opencv-contrib-python==4.10.0.84
numpy==1.26.4
scipy==1.15.3
matplotlib==3.10.8
polars==1.37.1
psutil==7.2.1
pyyaml==6.0.3
requests==2.32.5
pillow==12.1.0
```

Instalar todo de golpe:

```bash
pip install -r requirements.txt
```

## ğŸ“ Notas

- El modelo espera imÃ¡genes RGB de 1280x720
- La sincronizaciÃ³n RGB-Depth usa `ApproximateTimeSynchronizer` con slop=0.1s
- Los parÃ¡metros intrÃ­nsecos de la cÃ¡mara estÃ¡n hardcodeados (fx=fy=634.08)
- La orientaciÃ³n se calcula usando PCA sobre los puntos de la mÃ¡scara

## ğŸ“§ Contacto

Para dudas o problemas, revisa los logs de ROS2:

```bash
ros2 topic echo /rosout
```

---

**VersiÃ³n:** 1.0  
**Ãšltima actualizaciÃ³n:** Enero 2026
